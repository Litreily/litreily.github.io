<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="simple life"><meta name="theme-color" content="#2d4356"><meta name="baidu-site-verification" content="pte8o83UGG"><title>LITREILY</title><link rel="stylesheet" type="text/css" href="/css/style.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.png"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script><script>var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?d55250b3059d32736607d30baa6e0ca2";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();</script><meta name="generator" content="Hexo 5.3.0"></head><script type="text/javascript" src="/js/ready.js" async></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><body class="night"><div class="mobile-head" id="mobile-head"><div class="navbar-icon"><span></span><span></span><span></span></div><div class="navbar-title"><a href="/">LITREILY</a></div><div class="navbar-search"><!--= show a circle here--></div></div><div class="h-wrapper" id="menu"><nav class="h-head box"><div class="m-hdimg"><a class="hdimg img" href="/"><img class="nofancybox" src="/img/profile.jpg" width="128" height="128"></a><h1 class="ttl"><a href="/">LITREILY</a></h1></div><p class="m-desc">心之所向，无惧无悔,<br>愿求仁得仁，复无怨怼！</p><div class="m-nav"><ul><li><span class="dot">●</span><a href="/archives/">归档</a></li><li><span class="dot">●</span><a href="/categories/">分类</a></li><li><span class="dot">●</span><a href="/tags/">标签</a></li><li><span class="dot">●</span><a href="/about/">关于</a></li><li><span class="dot">●</span><a href="/notes/">笔记</a></li><li><span class="dot">●</span><a href="/atom.xml">RSS</a></li><li class="m-sch"><form class="form" id="j-formsch" method="get"><input class="txt" type="text" id="local-search-input" name="q" value="搜索" onfocus="if(this.value=='搜索'){this.value='';}" onblur="if(this.value==''){this.value='搜索';}"><input type="text" style="display:none;"></form></li></ul><div id="local-search-result"></div></div></nav></div><div id="back2Top"><a class="fa fa-arrow-up" title="Back to top" href="#"></a></div><div class="box" id="container"><div class="l-wrapper"><div class="l-content box"><div class="l-postlist"><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/03/03/qqzone/">Python网络爬虫5 - 爬取QQ空间相册</a></h1><div class="p-content"><p>自毕业后，就再也没有用过QQ，QQ空间里记录的是些并不精彩的青葱岁月，但好歹也是份回忆，近日想着学以致用，用<code>Python</code>把QQ空间相册的所有照片爬取下来，以作备份。</p>
<h2 id="分析QQ空间"><a href="#分析QQ空间" class="headerlink" title="分析QQ空间"></a>分析QQ空间</h2><h3 id="登录QQ空间"><a href="#登录QQ空间" class="headerlink" title="登录QQ空间"></a>登录QQ空间</h3><p>爬取第一步，分析站点，首先需要知道如何登录QQ空间。最初想法是用<code>requests</code>库配置登录请求，模拟登录，但是不久便放弃了这一思路，请看下图↓</p></div><p class="p-readmore"><a href="/2019/03/03/qqzone/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/03/03/qqzone/">2019-03-03</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Language/">Language</a>&nbsp;&bull;&nbsp;<a href="/categories/Language/Python/">Python</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/spider/">spider</a><a href="/tags/qqzone/">qqzone</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/02/27/ipv6/">记一次Client无法获取IPv6地址问题的分析过程</a></h1><div class="p-content"><p>近日SQA报了一个bug，对路由器经过6天左右的压力测试后，无论是有线设备还是无线设备都拿不到<code>IPv6</code>地址了。经过层层分析发现可能是<code>kernel</code>内存泄漏。本文便记录这一问题的分析过程。</p></div><p class="p-readmore"><a href="/2019/02/27/ipv6/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/02/27/ipv6/">2019-02-27</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Embedded/">Embedded</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/IPv6/">IPv6</a><a href="/tags/router/">router</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/02/17/mount/">Ubuntu开机自动挂载Windows系统中的磁盘分区</a></h1><div class="p-content"><p>本人电脑装有<code>ubuntu</code>和<code>windows</code>双系统，有时候需要在<code>ubuntu</code>下使用<code>windows</code>系统下的文件，每次手动挂载的话很麻烦，所以想让它开机自动挂载常用的<code>windows</code>磁盘分区。</p></div><p class="p-readmore"><a href="/2019/02/17/mount/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/02/17/mount/">2019-02-17</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Linux/">Linux</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/ubuntu/">ubuntu</a><a href="/tags/mount/">mount</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/02/14/XSS/">XSS跨站脚本攻击</a></h1><div class="p-content"><p>近期遇到一堆 Stored XSS vulnerability 问题，即存储型跨站脚本漏洞，所以有必要学习一下XSS相关的知识。</p>
<h2 id="XSS简介"><a href="#XSS简介" class="headerlink" title="XSS简介"></a>XSS简介</h2><p><code>XSS</code>是跨站脚本<code>Cross-Site Scripting</code>的简写，至于为什么不是<code>CSS</code>，相信大家很容易猜到，是为了避免与前端的层叠样式表<code>Cascading Style Sheets</code>重名。</p>
<p><code>XSS</code>涉及三个要素：一个站点，攻击者和受害者。攻击者通过某站点的漏洞注入脚本到该站点，受害者在使用浏览器访问该站点时就可能遭受<code>XSS</code>攻击。</p>
<p>脚本类型不限于<code>javascript</code>, 也可以是其它脚本，如<code>VBScript</code>, <code>ActiveX</code> 和 <code>flash</code>等，但主要还是以<code>javascript</code>为主。</p></div><p class="p-readmore"><a href="/2019/02/14/XSS/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/02/14/XSS/">2019-02-14</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Network/">Network</a>&nbsp;&bull;&nbsp;<a href="/categories/Network/Security/">Security</a></span><span class="p-tags"><i class="fa fa-tag"></i><a href="/tags/xss/">xss</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2019/01/22/highcharts/">Python之MongoDB数据分析及其Highcharts可视化</a></h1><div class="p-content"><p>近期使用<code>requests</code>把内部<code>bugziila</code>上的<code>bug</code>数据爬取了一遍，并存入了本地的<code>MongoDB</code>数据库，想着对数据做些简单的可视化处理，将所有产品的bug数做一个统计和可视化，于是便有了这篇简短的文章。</p></div><p class="p-readmore"><a href="/2019/01/22/highcharts/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2019/01/22/highcharts/">2019-01-22</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Language/">Language</a>&nbsp;&bull;&nbsp;<a href="/categories/Language/Python/">Python</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/visualization/">visualization</a><a href="/tags/MongoDB/">MongoDB</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2018/12/31/pypcap-install/">Python之pypcap库的安装及简单抓包工具的实现</a></h1><div class="p-content"><p><a target="_blank" rel="noopener" href="https://github.com/pynetwork/pypcap">pypcap</a>是一个对<code>libpcap</code>C库进行封装和简化的面向对象的抓包工具库，可以非常方便的用于抓包和过滤，结合<code>dpkt</code>解析库可以完成许多网络数据包的抓取和分析。本文讲述的就是如何使用<code>pypcap</code>及<code>dpkt</code>库实现简单抓包工具，也称为嗅探器(sniffer).</p>
<h2 id="Linux-端安装-pypcap"><a href="#Linux-端安装-pypcap" class="headerlink" title="Linux 端安装 pypcap"></a>Linux 端安装 pypcap</h2><pre><code class="bash">sudo apt-get install libpcap-dev
sudo pip install pypcap</code></pre>
<p>这里有个问题,如果使用<code>Anaconda</code>目录的<code>pip</code>安装则可能失败,目前原因未明,但官方的<code>python3</code>对应的<code>pip3</code>及<code>python2</code>对应的<code>pip</code>均无此问题.</p></div><p class="p-readmore"><a href="/2018/12/31/pypcap-install/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2018/12/31/pypcap-install/">2018-12-31</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Language/">Language</a>&nbsp;&bull;&nbsp;<a href="/categories/Language/Python/">Python</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/pypcap/">pypcap</a><a href="/tags/dpkt/">dpkt</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2018/11/25/autossh/">autossh反向代理实现内网穿透</a></h1><div class="p-content"><p>有时候需要在公司使用家里个人PC的一些资源，此时可以选择<code>Teamvieawer</code>进行远程，但是略微麻烦而且访问速率较慢，此时通过<code>vps</code>实现内网穿透就是个不错的想法。</p>
<p><img src="/assets/proxy/autossh_proxy.svg" alt="vps proxy"></p>
<p>本文讲述的内网穿透方法是通过<code>autossh</code>实现vps对内网的反向代理，在vps与内网之间建立一条长连接，使得外网PC通过vps的反向代理访问内网PC。整个实现所需的条件如下：</p>
<ol>
<li>带有公网IP(<code>222.222.222.222</code>)的vps</li>
<li>保持开机且联网的内网PC</li>
<li>任一联网的外网PC</li>
</ol></div><p class="p-readmore"><a href="/2018/11/25/autossh/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2018/11/25/autossh/">2018-11-25</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Network/">Network</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/ssh/">ssh</a><a href="/tags/proxy/">proxy</a><a href="/tags/vps/">vps</a></span></div></div><div class="l-post"><div class="p-desc box"><div class="p-pic"></div><h1 class="p-title"><a href="/2018/10/25/io-cache/">Linux中的文件I/O缓冲</a></h1><div class="p-content"><p>近日阅读《Linux/UNIX系统编程手册》第13章 - 文件I/O缓冲，有些收获，是以此文以记之。以往只知道Linux的I/O操作有缓冲机制，但始终不知道具体的缓冲流程及使用方法。读完本章节后方才有种恍然大悟的感觉，久违的因读书而觉得舒爽的感觉。</p>
<p>好了，进入正题，下图摘自原文(13.4-I/O缓冲小结)，此图概括了<code>stdio</code>库及内核针对输出文件所用的缓冲以及各类缓冲的控制机制。本文依据此图逐步揭开文件I/O缓冲的面纱。</p>
<p><img src="/assets/linux/io_buffer.jpg" alt="I/O缓冲"></p></div><p class="p-readmore"><a href="/2018/10/25/io-cache/">阅读更多 &gt;&gt;</a></p></div><div class="p-info box"><span class="p-date"><i class="fa fa-calendar"></i><a href="/2018/10/25/io-cache/">2018-10-25</a></span><span class="p-category"><i class="fa fa-folder"></i><a href="/categories/Linux/">Linux</a></span><span class="p-tags"><i class="fa fa-tags"></i><a href="/tags/stdio/">stdio</a><a href="/tags/cache/">cache</a><a href="/tags/buffer/">buffer</a></span></div></div></div><div class="l-pager l-pager-id box" id="page-nav"><a class="extend prev" rel="prev" href="/page/4/">&lt;上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/6/">下一页&gt;</a></div><footer><p>Copyright © 2016 - 2020 <a href="/." rel="nofollow">LITREILY</a> | <strong><a rel="nofollow" target="_blank" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></strong><br><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span></span> <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span></span> | Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a>Theme with<a rel="nofollow" target="_blank" href="https://github.com/litreily/snark-hexo"> snark.</a></p></footer></div></div></div><script type="text/javascript" src="/js/search.js"></script><script type="text/javascript" src="/js/top.js"></script><script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
    search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.1" async></script></body></html>